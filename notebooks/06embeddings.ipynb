{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ejercicio 6: Dense Retrieval e Introducción a FAISS\n",
    "\n",
    "## Objetivo de la práctica\n",
    "\n",
    "Generar embeddings con sentence-transformers (SBERT, E5), e indexar documentos con FAISS "
   ],
   "id": "d3f8b5c16e7eb563"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 0: Carga del Corpus\n",
    "### Actividad\n",
    "\n",
    "1. Carga el corpus 20 Newsgroups desde sklearn.datasets.fetch_20newsgroups.\n",
    "2. Limita el corpus a los primeros 2000 documentos para facilitar el procesamiento."
   ],
   "id": "cdd69ed7fcbeef9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b00fbde6cfc88b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 2: Generación de Embeddings\n",
    "### Actividad\n",
    "\n",
    "1. Usa dos modelos de sentence-transformers. Puedes usar: `'all-MiniLM-L6-v2'` (SBERT), o `'intfloat/e5-base'` (E5). Cuando uses E5, antepon `\"passage: \"` a cada documento antes de codificar.\n",
    "2. Genera los vectores de embeddings para todos los documentos usando el modelo seleccionado.\n",
    "3. Guarda los embeddings en un array de NumPy para su posterior indexación."
   ],
   "id": "b9184f4b3e66e20a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "525ae7515c6169d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 3: Indexación con FAISS\n",
    "### Actividad\n",
    "\n",
    "1. Crea un índice plano con faiss.IndexFlatL2 para búsquedas por distancia euclidiana.\n",
    "2. Asegúrate de usar la dimensión correcta `(embedding_dim = doc_embeddings.shape[1])`.\n",
    "3. Agrega los vectores de documentos al índice."
   ],
   "id": "e53b50365064d2b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "96c723e6189ab1fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parte 4: Consulta Semántica\n",
    "### Actividad\n",
    "\n",
    "1. Escribe una consulta en lenguaje natural. Ejemplos:\n",
    "\n",
    "    * \"God, religion, and spirituality\"\n",
    "    * \"space exploration\"\n",
    "    * \"car maintenance\"\n",
    "\n",
    "2. Codifica la consulta utilizando el mismo modelo de embeddings. Cuando uses E5, antepon `\"query: \"` a la consulta.\n",
    "3. Recupera los 5 documentos más relevantes con `index.search(...)`.\n",
    "4. Muestra los textos de los documentos recuperados (puedes mostrar solo los primeros 500 caracteres de cada uno)."
   ],
   "id": "40462a067ca2d379"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aad085806124c709"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2dc9e5e7815c7508"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
